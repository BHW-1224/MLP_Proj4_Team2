{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e4e989",
   "metadata": {
    "papermill": {
     "duration": 0.001487,
     "end_time": "2025-11-23T07:37:29.337210",
     "exception": false,
     "start_time": "2025-11-23T07:37:29.335723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2 — Simple LightGBM Model\n",
    "LightGBM을 사용하여 시계열 train/validation split로 학습하는 기본 모델."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5414d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:37:29.340602Z",
     "iopub.status.busy": "2025-11-23T07:37:29.340375Z",
     "iopub.status.idle": "2025-11-23T07:37:48.252417Z",
     "shell.execute_reply": "2025-11-23T07:37:48.251171Z"
    },
    "papermill": {
     "duration": 18.915836,
     "end_time": "2025-11-23T07:37:48.254152",
     "exception": false,
     "start_time": "2025-11-23T07:37:29.338316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 2: Simple Baseline LightGBM Model ===\n",
      "Total usable features: 94\n",
      "Train size: 8841,  Val size: 180\n",
      "Training LightGBM...\n",
      "Training finished.\n",
      "\n",
      "=== STEP 2 Validation RMSE: 0.011852002479 ===\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2 — Baseline LightGBM (Leakage-free, Time-based Split)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "TRAIN_PATH = \"/kaggle/input/hull-tactical-market-prediction/train.csv\"\n",
    "TARGET_NAME = \"market_forward_excess_returns\"\n",
    "\n",
    "print(\"=== STEP 2: Simple Baseline LightGBM Model ===\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load & Sort Data\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(TRAIN_PATH).sort_values(\"date_id\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Leakage-free Feature Selection\n",
    "#    (미래 수익 관련 feature로 포함 X)\n",
    "# ------------------------------------------------------------\n",
    "leak_cols = [\n",
    "    \"date_id\",\n",
    "    \"forward_returns\",                # 실제 미래 수익\n",
    "    \"risk_free_rate\",\n",
    "    TARGET_NAME                       # 예측 대상 (market_forward_excess_returns)\n",
    "]\n",
    "\n",
    "# feature 추출 (M*, V*, E*, I*, S*, P*, D*, MOM*)\n",
    "feature_cols = [c for c in df.columns if c not in leak_cols]\n",
    "\n",
    "print(f\"Total usable features: {len(feature_cols)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Time-based Train/Validation Split\n",
    "# ------------------------------------------------------------\n",
    "dates = np.sort(df[\"date_id\"].unique())\n",
    "\n",
    "# 마지막 180일을 validation으로\n",
    "val_days = 180\n",
    "train_dates = dates[:-val_days]\n",
    "val_dates   = dates[-val_days:]\n",
    "\n",
    "train_df = df[df[\"date_id\"].isin(train_dates)]\n",
    "val_df   = df[df[\"date_id\"].isin(val_dates)]\n",
    "\n",
    "X_tr, y_tr = train_df[feature_cols].fillna(0), train_df[TARGET_NAME]\n",
    "X_va, y_va = val_df[feature_cols].fillna(0), val_df[TARGET_NAME]\n",
    "\n",
    "print(f\"Train size: {len(X_tr)},  Val size: {len(X_va)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. LightGBM Parameters\n",
    "# ------------------------------------------------------------\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"verbosity\": -1,  \n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Train Model\n",
    "# ------------------------------------------------------------\n",
    "dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "model = lgb.train(params, dtrain, num_boost_round=1500)\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Validation RMSE\n",
    "# ------------------------------------------------------------\n",
    "pred = model.predict(X_va)\n",
    "rmse = np.sqrt(np.mean((pred - y_va) ** 2))\n",
    "\n",
    "print(f\"\\n=== STEP 2 Validation RMSE: {rmse:.12f} ===\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.177384,
   "end_time": "2025-11-23T07:37:48.872879",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-23T07:37:25.695495",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
